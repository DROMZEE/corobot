{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Chatbot-infos-corona\" data-toc-modified-id=\"Chatbot-infos-corona-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Chatbot infos corona</a></span><ul class=\"toc-item\"><li><span><a href=\"#Rendez-votre-chatbot-encore-plus-intelligent!\" data-toc-modified-id=\"Rendez-votre-chatbot-encore-plus-intelligent!-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Rendez votre chatbot encore plus intelligent!</a></span></li><li><span><a href=\"#Bonus-avec-stemmatizer-:\" data-toc-modified-id=\"Bonus-avec-stemmatizer-:-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Bonus avec stemmatizer :</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chatbot infos corona\n",
    "\n",
    "Dans ce cas pratique on va essayer d'entraîner un chatbot qui permette de répondre automatiquement aux questions de l'utilisateur sur le coronavirus à partir de multiples informations que l'on a regroupées dans le fichier `infos_corona.txt`. L'idée est que le chatbot renvoie la ou les phrases utilisant le plus de termes similaires à ceux utilisés dans la question de l'utilisateur.   \n",
    "La démarche est similaire à celle présentée dans le notebook `chatbot_wiki`.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- En utilisant la fonction `open` (et en précisant le paramètre `encoding` adéquat!), importez le texte dans une chaîne de caractères que vous nommerez `texte`.  \n",
    "- Procédez à quelques nettoyages : \n",
    "    - passez le texte en minuscules.  \n",
    "    - un acronyme (n.c.a.) va fausser notre tokenization en phrases, remplacez-le par autre chose.  \n",
    "    - le virus est appelé covid-19 ou coronavirus, faites en sorte qu'un terme unique soit utilisé.   \n",
    "- Avec la fonction `nltk.sent_tokenize`, passez votre chaîne de caractères `texte` en une liste de phrases que vous appelerez `phrases_token`.  \n",
    "- Il y a beaucoup de questions dans cette liste, or on veut des réponses. Supprimez-les (_une méthode_ : boucle sur la liste et suppression avec `del` des éléments contenant un \"?\". __Attention__ : il faut faire partir la boucle de l'indice le plus grand vers 0, sinon le fait de supprimer des éléments fausse l'indexation!).     \n",
    "- Récupérez un vecteur de stop words français avec la fonction `get_stop_words` du module `stop_words` \n",
    "\n",
    "On a maintenant tout ce dont on a besoin pour faire notre matrice TF-IDF! Vous pouvez déjà la fitter sur vos infos :  \n",
    "- Stockez le résultat de `TfidfVectorizer` en fixant le paramètre `stop_words` avec les stop words français.  \n",
    "- Fittez la fonction sur votre liste de phrases `phrases_token` et stockez ce résultat dans un objet `tf_idf_chat`.  \n",
    "\n",
    "Il faut maintenant définir une fonction que vous appelerez dans votre chatbot. Celle-ci doit :  \n",
    "- Prendre en entrée la phrase entrée par l'utilisateur et la mettre dans une liste.    \n",
    "- Créer la matrice TF-IDF des infos avec `tf_idf_chat.transform()`. \n",
    "- Créer la matrice TF-IDF pour la phrase de l'utilisateur avec `tf_idf_chat.transform()`.  \n",
    "- Calculez la similarité entre la phrase de l'utilisateur et le reste des phrases avec `sklearn.metrics.pairwise.cosine_similarity`.  \n",
    "- Renvoyer en réponse la phrase avec la similarité la plus grande, ou un message d'erreur s'il n'y a pas de similarité. _Alternative un peu plus complexe_ : Vous pouvez aussi renvoyer plusieurs phrases si plusieurs sont similaires, en les concaténant dans une même chaîne de caractère avec '\\n'.join().  \n",
    "\n",
    "Maintenant il n'y a plus qu'à intégrer cette fonction dans votre chatbot et le tester! N'oubliez pas de lui faire dire bonjour et de laisser la possibilité à l'utilisateur de quitter! Bon courage! \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rendez votre chatbot encore plus intelligent!  \n",
    "Donnez la possibilité à l'utilisateur de nourrir le chatbot de nouvelles informations. Vous pouvez par exemple déterminer qu'après avoir tapé \"infos\", l'utilisateur va rentrer une phrase que vous devrez ajouter aux possibilités de réponses de votre chatbot.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus avec stemmatizer : \n",
    "\n",
    "On définit maintenant une fonction à indiquer dans le paramètre `tokenizer` de la fonction `TfidfVectorizer`. Cette fonction doit récupérer la racine des mots plutôt que les mots en entier pour trouver des correspondances entre des mots de la même racine même s'ils ne sont pas écrits sous la même forme.  \n",
    "- Utilisez la fonction `FrenchStemmer` de `nltk.stem.snowball` pour définir :  \n",
    "    - une première fonction qui renvoie la liste des mots stemmatisés quand on rentre une liste de mots.  \n",
    "    - Une fonction qui applique cette première fonction à une phrase qu'on tokenize en mots (avec `nltk.word_tokenize`)  \n",
    "Vous pouvez tester cette fonction sur des phrases pour voir si elle fait bien ce que vous désirez.  \n",
    "- Ajoutez l'appel à cette fonction dans `TfidfVectorizer`.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
